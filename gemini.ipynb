{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":568.720153,"end_time":"2024-07-10T14:14:16.227578","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-10T14:04:47.507425","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00d2bc580c3945de9c9f8c86e8856cc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14615602089743c0897b5c9fab4cf585","placeholder":"​","style":"IPY_MODEL_6486f1cd27574d2ab6d462733d84e15c","value":"100%"}},"0a91d365fae34f419e9ff1f5a382f965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d0f9e3aca2246bc8cf7cd1418db24f2","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_257fe29936b64b4583237192b416b874","value":3}},"14615602089743c0897b5c9fab4cf585":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257fe29936b64b4583237192b416b874":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48780eeb3f1a40918b582e26d2f110bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d0f9e3aca2246bc8cf7cd1418db24f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57f2f2c7d1ad46b2a7472e7d1ac73279":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6486f1cd27574d2ab6d462733d84e15c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78a86b9c009d425f9b0dfd02f1139c19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df0d5a21e46b4b34aa0316937fba5c0b","placeholder":"​","style":"IPY_MODEL_48780eeb3f1a40918b582e26d2f110bb","value":" 3/3 [09:17&lt;00:00, 216.47s/it]"}},"8b527345c8af442798f4615152a9ca51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00d2bc580c3945de9c9f8c86e8856cc7","IPY_MODEL_0a91d365fae34f419e9ff1f5a382f965","IPY_MODEL_78a86b9c009d425f9b0dfd02f1139c19"],"layout":"IPY_MODEL_57f2f2c7d1ad46b2a7472e7d1ac73279"}},"df0d5a21e46b4b34aa0316937fba5c0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load the Datasets","metadata":{"papermill":{"duration":0.006008,"end_time":"2024-07-10T14:04:50.969194","exception":false,"start_time":"2024-07-10T14:04:50.963186","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# References\n2/3 Solved - Gemini Generates Solutions Sometimes\n\n# Changes to [Original Notebook](https://www.kaggle.com/code/millernicholas/arc-prize-chatgpt4o-writes-solution-algorithms)\n\n- Use Gemini instead of GPT-4o because OpenAI API costs money, which is not as accessible\n- Iteratively test code until it works on the train set (no leakage)\n- LLM is aware of previous attempts, actively tries new strategies\n- Pictures of images are now supported, you can input images and prompt to the model simultaneously\n- Examples are only 3 due to qouta limits","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport subprocess\n\nuser_secrets = UserSecretsClient()\ngemini_api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n\ncommand = f\"\"\"\ncurl -X POST \\\n    -H \"X-goog-api-key: {gemini_api_key}\" \\\n    -H \"Content-Type: application/json; charset=utf-8\" \\\n    -d '{{\"q\": \"Hello, world!\", \"target\": \"es\"}}' \\\n    \"https://translation.googleapis.com/language/translate/v2\"\n\"\"\"\n\n# Execute the command\nresult = subprocess.run(command, shell=True, capture_output=True, text=True)\n\n# Print the output\nprint(result.stdout)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:02:47.612380Z","iopub.execute_input":"2024-08-16T14:02:47.612882Z","iopub.status.idle":"2024-08-16T14:02:47.946219Z","shell.execute_reply.started":"2024-08-16T14:02:47.612849Z","shell.execute_reply":"2024-08-16T14:02:47.944803Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Cloud Translation API has not been used in project 1049567400392 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=1049567400392 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\",\n    \"errors\": [\n      {\n        \"message\": \"Cloud Translation API has not been used in project 1049567400392 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=1049567400392 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\",\n        \"domain\": \"usageLimits\",\n        \"reason\": \"accessNotConfigured\",\n        \"extendedHelp\": \"https://console.developers.google.com\"\n      }\n    ],\n    \"status\": \"PERMISSION_DENIED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Google developers console API activation\",\n            \"url\": \"https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=1049567400392\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n        \"reason\": \"SERVICE_DISABLED\",\n        \"domain\": \"googleapis.com\",\n        \"metadata\": {\n          \"service\": \"translate.googleapis.com\",\n          \"consumer\": \"projects/1049567400392\"\n        }\n      }\n    ]\n  }\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nimport time\n\nimport google.generativeai as genai\nimport PIL.Image\nimport textwrap\n\nfrom kaggle_secrets import UserSecretsClient\nfrom IPython.display import Image, Markdown\nuser_secrets = UserSecretsClient()\ngemini_api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n\n# verify operational\ngenai.configure(api_key=gemini_api_key)\nmodel = genai.GenerativeModel(model_name='gemini-1.5-pro')\nresponse = model.start_chat(history=[]).send_message(\"Hello, world!\").text\nprint(response)","metadata":{"papermill":{"duration":1.644315,"end_time":"2024-07-10T14:04:52.619336","exception":false,"start_time":"2024-07-10T14:04:50.975021","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-16T13:59:12.178536Z","iopub.execute_input":"2024-08-16T13:59:12.178943Z","iopub.status.idle":"2024-08-16T13:59:12.953623Z","shell.execute_reply.started":"2024-08-16T13:59:12.178912Z","shell.execute_reply":"2024-08-16T13:59:12.951187Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mgemini_api_key)\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-1.5-pro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello, world!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:504\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 504\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:258\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/client.py:239\u001b[0m, in \u001b[0;36m_ClientManager.make_client.<locals>.add_default_metadata_wrapper.<locals>.call\u001b[0;34m(metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39margs, metadata\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata)\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:812\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n","\u001b[0;31mFailedPrecondition\u001b[0m: 400 User location is not supported for the API use."],"ename":"FailedPrecondition","evalue":"400 User location is not supported for the API use.","output_type":"error"}]},{"cell_type":"code","source":"import json\n\ndatasets = {\n    'train':'/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json',\n    'train_solutions':'/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json',\n    'eval':'/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json',\n    'eval_soultions':'/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json',\n    'test':'/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json',\n    'sample_sub':'/kaggle/input/arc-prize-2024/sample_submission.json',\n}\ndata = {}\nfor k,v in datasets.items():\n    with open(v, 'r') as f:\n        text = f.read()\n        data[k] = json.loads(text)\nsubset = {}\nfor i,(k,v) in enumerate(data['test'].items()):\n    if i<3:\n        subset[k] = v\ndata['test'] = subset\n    \nlen(data['train']), len(data['test'])","metadata":{"papermill":{"duration":0.465558,"end_time":"2024-07-10T14:04:53.090584","exception":false,"start_time":"2024-07-10T14:04:52.625026","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-16T13:22:57.119995Z","iopub.execute_input":"2024-08-16T13:22:57.120381Z","iopub.status.idle":"2024-08-16T13:22:57.442742Z","shell.execute_reply.started":"2024-08-16T13:22:57.120348Z","shell.execute_reply":"2024-08-16T13:22:57.441512Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(400, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Visualize the Input and Output","metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:06:24.284943Z","iopub.status.busy":"2024-06-20T13:06:24.284497Z","iopub.status.idle":"2024-06-20T13:06:24.292769Z","shell.execute_reply":"2024-06-20T13:06:24.291655Z","shell.execute_reply.started":"2024-06-20T13:06:24.28491Z"},"papermill":{"duration":0.005755,"end_time":"2024-07-10T14:04:53.102752","exception":false,"start_time":"2024-07-10T14:04:53.096997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nimport matplotlib.ticker as ticker\n\n# Copied and modified from: https://www.kaggle.com/code/arwani/auto-encoder/notebook\ndef plot(record, save = False):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n\n    norm = colors.Normalize(vmin=0, vmax=10)\n    def remove_tail_zeros(key, data, mode = 'inp'):\n        data = data.cpu().numpy()\n        data = data.astype(int)\n        ndata = []\n        for i in range(len(data)):\n            ndata.append(data[i] - 1 if data[i] > 0 else 0)\n        data = np.array(ndata)\n        dim = Dimension[key]['inp_dim' if mode == 'inp' else 'out_dim']\n        return data[:dim[0] * dim[1]].reshape(dim[0], dim[1])\n    \n    num_rows = len(record)\n    num_cols = len(record[0])\n    fig, ax = plt.subplots(num_rows, num_cols, figsize=(num_cols*2,num_rows*2,), sharex=True,sharey=True)\n    for x in range(num_rows):\n        for y in range(num_cols):\n            name = list(record[x].keys())[y]\n            if num_rows > 1 and num_cols > 1:\n                sub_plot = ax[x,y]\n            elif num_rows > 1:\n                sub_plot = ax[x]\n            else:\n                sub_plot = ax[y]\n            if record[x][name]:\n                try:\n                    sub_plot.imshow(record[x][name], cmap=cmap, norm=norm)\n                    sub_plot.set_title(name) if x==0 else None\n                    sub_plot.xaxis.set_major_locator(ticker.NullLocator())\n                    sub_plot.yaxis.set_major_locator(ticker.NullLocator())\n                except:\n                    pass\n    if save:\n        plt.savefig('img.png')\n    else:\n        plt.show()\n    \nsample_key = next(iter(data['train']))\n\n# Plot the training\nplot(data['train'][sample_key]['train'])\n\n# plot the test and result\nplot([{\n    'test':data['train'][sample_key]['test'][0]['input'],\n    'expected':data['train_solutions'][sample_key][0],\n}])","metadata":{"papermill":{"duration":0.850263,"end_time":"2024-07-10T14:04:53.958947","exception":false,"start_time":"2024-07-10T14:04:53.108684","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-16T13:23:10.357026Z","iopub.execute_input":"2024-08-16T13:23:10.357426Z","iopub.status.idle":"2024-08-16T13:23:11.163904Z","shell.execute_reply.started":"2024-08-16T13:23:10.357394Z","shell.execute_reply":"2024-08-16T13:23:11.162604Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 400x1000 with 10 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x200 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport copy\nfrom tqdm.notebook import tqdm\nimport pathlib\n\nFORCE_RUN = True\nSUBMISSION_FILE_NAME = 'submission_with_code.json'\n\nMODEL = 'gemini-1.5-pro'\nTRIES = 15\nUSE_PICTURE = False\n\n# Make Gemini Deterministic\nTEMPERATURE = 0\nTOP_K = 3\nTOP_P = 0.1\n\nSYSTEM_PROMPT = \"\"\"You are a very clever agent and python programmer who is able to reason complex pattern algorithms based on a few examples that show one matrix transforming into another in JSON format\"\"\"\nUSER_PROMPT = \"\"\"Here are a few examples of a transformation pattern from `input` to `output`:\n\n```json\n{input_string}\n```\n\nWrite a python algorithm that can generate the correct output for a given input based on the shared pattern in the examples such that it will work for an unseen example input.\nThink carefully to understand what is causing the difference between the input and the output.\nWrite your thought process in code comments such as what the transformation is anologous to in the physical world or how a child might explain what the algorithm is doing.\nEach number in the input and output corresponds to a color in an image in the real world, as such the transformation may be a little abstract, such as fitting an image onto itself, or filling in blanks. Usually, 0 represents an empty space.\nUsing your comments as a guide, think through the code step-by-step and make sure the code is executable and produces the expected output for the examples provided.\nRespond with just the algorithm. No introduction, no explanation, no summary, no tests.  Any thoughts should be in code comments.\nUse the following template for your algorithm:\n\n```python\nimport numpy as np\n\n# Your thought process\ndef apply_transformation(input_matrix):\n    # perform transformation\n    ...\n    return output_matrix\n```\n\"\"\"\n\nREDO_USER_PROMPT = \"\"\"\n\nIt seems like the previous solution does not work, even when applied to the example data. If the output is significantly different to your algorithm's output, please find a completely new unique solution. Here are the examples: `input`, `output` and  `your output`:\n\n```json\n{input_string}\n```\n\nOnce again, rewrite a python algorithm that can generate the correct output for a given input based on the shared pattern in the examples such that it will work for an unseen example input.\nDo not to hardcode patterns, make it dynamic and fully dependent on the inputs given.\nThink carefully to understand what is causing the outputs to change and how that is related to the inputs.\nUsing your comments as a guide, think through the code step-by-step and make sure the code is executable and produces the expected output for the examples provided.\nRespond with just the algorithm. No introduction, no explanation, no summary, no tests.  Any thoughts should be in code comments.\nUse the following template for your algorithm:\n\n```python\nimport numpy as np\n\n# Your thought process\ndef apply_transformation(input_matrix):\n    # perform transformation\n    ...\n    return output_matrix\n```\n\"\"\"\nBASE_RESPONSE = [[0, 0], [0, 0]]\n\ndef generate_user_prompt(input_string):\n    return USER_PROMPT.replace('{input_string}', json.dumps(input_string))\n\ndef generate_redo_user_prompt(input_string):\n    return REDO_USER_PROMPT.replace('{input_string}', json.dumps(input_string))\n\ndef generate_image(input_string):\n    plot(input_string,True)\n    return {\n        'mime_type': 'image/png',\n        'data':pathlib.Path('img.png').read_bytes(),\n    }\n\ndef exec_response(response, input_matrix):\n    try:\n        pattern = r'```python\\n(.*?)```'\n        matches = re.findall(pattern, response, re.DOTALL)\n        code = matches[0]\n        code += '\\nresult = apply_transformation(input_matrix)'\n    except Exception as e:\n        raise Exception(f\"ERROR: Unable to extract python code from response.\\nResponse: {response}\\nError: {e}\")\n\n    global_scope = {'np': np}\n    local_scope = {'input_matrix': input_matrix}\n    try:\n        exec(code, global_scope, local_scope)\n        if 'result' in local_scope:\n            result = local_scope['result']\n            return result, code\n        else:\n            raise Exception(\"ERROR: No result in local scope\")\n    except Exception as e:\n        raise Exception(f\"ERROR: Failed to run the code.\\nCode: {code}\\nError: {e}\")\n    \n    raise Exception(\"ERROR: Unexpected error\")\n\nif not FORCE_RUN and os.path.exists(SUBMISSION_FILE_NAME):\n    with open (SUBMISSION_FILE_NAME, 'r') as f:\n        results = json.loads(f.read())\nelse:\n    \n    genai.configure(api_key = gemini_api_key)\n    config = genai.types.GenerationConfig(\n        temperature = TEMPERATURE,\n        top_p = TOP_P,\n        top_k = TOP_K,\n    )\n    model = genai.GenerativeModel(model_name='gemini-1.5-pro',generation_config = config)\n    \n    results = {}\n\n    for k,v in tqdm(data['test'].items()):\n        train = v['train']\n        test = v['test']\n        \n        if USE_PICTURE:\n            user_prompt = [generate_user_prompt(train),generate_image(train)]\n        else:\n            user_prompt = [generate_user_prompt(train)]\n\n        # Ask Chat Bot\n        results[k] = []\n        chat = model.start_chat(history=[])\n        input_string = copy.deepcopy(train)\n        \n        result = {'done':False}\n        for try_idx in range(TRIES):\n            print(try_idx)\n            run = True\n            while run:\n                try:\n                    resp = chat.send_message(user_prompt).text\n                    run = False\n                except Exception as e:\n                    time.sleep(10)\n                    print(e)\n                    pass\n                \n            try:\n                output, code = exec_response(resp, test[0]['input'])\n                if not isinstance(output,list):\n                    output = output.tolist()\n                result[f'attempt_{try_idx+1}_output'] = output\n                result[f'attempt_{try_idx+1}_code'] = code\n            except:\n                user_prompt = 'the previous reponse threw exception, please try again'\n                result[f'attempt_{try_idx+1}_output'] = 'ERROR'\n                result[f'attempt_{try_idx+1}_code'] = 'ERROR'\n                continue\n            \n            wrong = False\n            for j in range(len(train)):\n                output, code = exec_response(resp, train[j]['input'])\n                if not np.array_equal(output, train[j]['output']):\n                    wrong=True\n    \n            output, code = exec_response(resp, test[0]['input'])\n            result[f'solution_output'] = output\n            result[f'solution_code'] = code\n            if not wrong:\n                result['done'] = True\n                break\n            \n            for j in range(len(train)):\n                output, code = exec_response(resp, train[j]['input'])\n                if not isinstance(output,list):\n                    output = output.tolist()\n                input_string[j]['your output'] = output\n                \n            if USE_PICTURE:\n                user_prompt = [generate_redo_user_prompt(input_string),generate_image(input_string)]\n            else:\n                user_prompt = [generate_redo_user_prompt(input_string)]\n        results[k] = [result]","metadata":{"papermill":{"duration":557.092403,"end_time":"2024-07-10T14:14:11.064282","exception":false,"start_time":"2024-07-10T14:04:53.971879","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-16T13:25:34.748815Z","iopub.execute_input":"2024-08-16T13:25:34.749727Z","iopub.status.idle":"2024-08-16T13:30:34.013015Z","shell.execute_reply.started":"2024-08-16T13:25:34.749687Z","shell.execute_reply":"2024-08-16T13:30:34.011414Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d4126cb89248769f77b770caf842d1"}},"metadata":{}},{"name":"stdout","text":"0\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n400 User location is not supported for the API use.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 144\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    145\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:504\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 504\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:258\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/client.py:239\u001b[0m, in \u001b[0;36m_ClientManager.make_client.<locals>.add_default_metadata_wrapper.<locals>.call\u001b[0;34m(metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:812\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n","\u001b[0;31mFailedPrecondition\u001b[0m: 400 User location is not supported for the API use.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 147\u001b[0m\n\u001b[1;32m    145\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 147\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Visualize some results","metadata":{"papermill":{"duration":0.013192,"end_time":"2024-07-10T14:14:11.090238","exception":false,"start_time":"2024-07-10T14:14:11.077046","status":"completed"},"tags":[]}},{"cell_type":"code","source":"exist = []\nfor k, _ in data['test'].items():\n    if k in data['train']:\n        exist.append(True)\n        print('.', end='')\n    else:\n        exist.append(False)\n        print('x', end='')\n\nif all(exist):\n    print(\"\\nAll keys in test set exist in train set\")\nelse:\n    print(\"\\nTest set has unique keys\")","metadata":{"execution":{"iopub.execute_input":"2024-07-10T14:14:11.119651Z","iopub.status.busy":"2024-07-10T14:14:11.119161Z","iopub.status.idle":"2024-07-10T14:14:11.128324Z","shell.execute_reply":"2024-07-10T14:14:11.126678Z"},"papermill":{"duration":0.028231,"end_time":"2024-07-10T14:14:11.131745","exception":false,"start_time":"2024-07-10T14:14:11.103514","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nfor sample_key in list(results.keys())[:3]:\n    # pick a random result\n\n    # display the training\n    plot(data['test'][sample_key]['train'])\n\n    # display the test and prediction\n    cur_plot = {\n        'test_input':data['test'][sample_key]['test'][0]['input'],\n        'expected': data['train_solutions'][sample_key][0],  # All keys in test exist in train solutions\n    }\n    for i in range(1,TRIES+1):\n        if f'attempt_{i}_output' in results[sample_key][0] and results[sample_key][0][f'attempt_{i}_output'] != 'ERROR':\n            cur_plot[f'predicted_{i}'] = results[sample_key][0][f'attempt_{i}_output']\n    plot([cur_plot])\n\n#     print(\"Here's the code that ChatGPT generated that created this solution:\\n\")\n#     for i in range(1,TRIES+1):\n#         print(results[sample_key][0].get(f'attempt_{i}_code','No code'))","metadata":{"execution":{"iopub.execute_input":"2024-07-10T14:14:11.163855Z","iopub.status.busy":"2024-07-10T14:14:11.162537Z","iopub.status.idle":"2024-07-10T14:14:15.207862Z","shell.execute_reply":"2024-07-10T14:14:15.206306Z"},"papermill":{"duration":4.064624,"end_time":"2024-07-10T14:14:15.211053","exception":false,"start_time":"2024-07-10T14:14:11.146429","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the results","metadata":{"papermill":{"duration":0.013836,"end_time":"2024-07-10T14:14:15.239706","exception":false,"start_time":"2024-07-10T14:14:15.22587","status":"completed"},"tags":[]}},{"cell_type":"code","source":"correct = 0\n# errors = 0\n\nfor k,v in results.items():\n    if v[0]['done']:\n        correct += 1\n\n# print(\"Errors:\", errors)\nprint(\"Correct:\", correct, 'of', len(results), f\"({correct/len(results)*100:.1f}%)\")","metadata":{"execution":{"iopub.execute_input":"2024-07-10T14:14:15.275815Z","iopub.status.busy":"2024-07-10T14:14:15.274236Z","iopub.status.idle":"2024-07-10T14:14:15.284132Z","shell.execute_reply":"2024-07-10T14:14:15.282303Z"},"papermill":{"duration":0.032251,"end_time":"2024-07-10T14:14:15.287653","exception":false,"start_time":"2024-07-10T14:14:15.255402","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Look for any errors","metadata":{"papermill":{"duration":0.017065,"end_time":"2024-07-10T14:14:15.320973","exception":false,"start_time":"2024-07-10T14:14:15.303908","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# errors = False\n# for k,v in results.items():\n#     if 'error' in v[0]:\n#         print(f\"Errors exist.\\nExample: {k} has error: {v[0]['error']}\")\n#         errors = True\n#         break\n# if not errors:\n#     print(\"No errors\")","metadata":{"execution":{"iopub.execute_input":"2024-07-10T14:14:15.355948Z","iopub.status.busy":"2024-07-10T14:14:15.355508Z","iopub.status.idle":"2024-07-10T14:14:15.36116Z","shell.execute_reply":"2024-07-10T14:14:15.359826Z"},"papermill":{"duration":0.025641,"end_time":"2024-07-10T14:14:15.364337","exception":false,"start_time":"2024-07-10T14:14:15.338696","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dump Submission","metadata":{"papermill":{"duration":0.015149,"end_time":"2024-07-10T14:14:15.39569","exception":false,"start_time":"2024-07-10T14:14:15.380541","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class FlexibleEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        # Let the base class default method raise the TypeError\n        return super(FlexibleEncoder, self).default(obj)\n    \nwith open(SUBMISSION_FILE_NAME, 'w') as f:\n    f.write(json.dumps(results, indent=4, cls=FlexibleEncoder))\n    \n# Cleanup the results by just adding attempts\nres = {k: [{'attempt_1': v[0]['solution_output']}] for k,v in results.items()}\n\njson_object = json.dumps(res, indent=4, cls=FlexibleEncoder)\nwith open('submission.json', 'w') as f:\n    f.write(json_object)","metadata":{"execution":{"iopub.execute_input":"2024-07-10T14:14:15.428017Z","iopub.status.busy":"2024-07-10T14:14:15.427577Z","iopub.status.idle":"2024-07-10T14:14:15.447498Z","shell.execute_reply":"2024-07-10T14:14:15.446204Z"},"papermill":{"duration":0.039784,"end_time":"2024-07-10T14:14:15.450778","exception":false,"start_time":"2024-07-10T14:14:15.410994","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Remarks\nThe LLMs perform much better on the data when they receive feedback and can try multiple different solutions, this is similar to [Ryan Greenblatt's approach](https://www.lesswrong.com/posts/Rdwui3wHxCeKb7feK/getting-50-sota-on-arc-agi-with-gpt-4o), which got 50% on ARC with GPT-4o after generating many code formats for every problem and finding one that worked.","metadata":{"papermill":{"duration":0.015643,"end_time":"2024-07-10T14:14:15.481764","exception":false,"start_time":"2024-07-10T14:14:15.466121","status":"completed"},"tags":[]}}]}